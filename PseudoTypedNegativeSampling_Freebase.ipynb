{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIsENvsf0shxbIkFgSRsnL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yalopez84/Goog-Negative-Sampling/blob/master/PseudoTypedNegativeSampling_Freebase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IfD-uUW9iqM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm, trange\n",
        "import random\n",
        "import csv\n",
        "from time import time\n",
        "import pdb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir=\"/content/drive/MyDrive/NegativeStrategies/GoodNegativeSampling/FB13/\"\n",
        "os.chdir(data_dir)"
      ],
      "metadata": {
        "id": "lGKnlShX9xd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputExample(object):    \n",
        "    def __init__(self, guid, text_a, text_b=None, text_c=None, label=None):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.text_c = text_c\n",
        "        self.label = label"
      ],
      "metadata": {
        "id": "9Pe2UQE2904P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Triple(object):\n",
        "    def __init__(self, guid, subject , predicate , obj, label):\n",
        "        self.guid=guid\n",
        "        self.subject=subject\n",
        "        self.predicate=predicate\n",
        "        self.obj=obj\n",
        "        self.label=label"
      ],
      "metadata": {
        "id": "FDnXM-Xb92yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relation_Dom_Ran(object):\n",
        "    \n",
        "    def __init__(self, relation, dom, rang, hpt=0,tph=0,pr=0):\n",
        "        self.relation = relation\n",
        "        self.dom = dom\n",
        "        self.rang = rang\n",
        "        self.hpt = hpt  \n",
        "        self.tph=tph\n",
        "        self.pr=pr"
      ],
      "metadata": {
        "id": "Iu0hh97A949L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CalcularBernoulliDistribution(relations=None, tripletas=None):\n",
        "    \n",
        "    for relation in relations:\n",
        "        listah=[]\n",
        "        listat=[]\n",
        "        canth,cantt,hpt,tph,pr=0,0,0,0,0       \n",
        "        for triple in tripletas:\n",
        "            temp=triple.split('\\t')\n",
        "            if temp[1]==relation.relation:\n",
        "                listah.append(temp[0])\n",
        "                listat.append(temp[2])\n",
        "        seth=set(listah)\n",
        "        sett=set(listat) \n",
        "        canth= len(seth)  \n",
        "        cantt= len(sett)\n",
        "        hpt=canth/cantt\n",
        "        tph=cantt/canth\n",
        "        pr=tph/(tph+hpt)        \n",
        "        relation.hpt=hpt\n",
        "        relation.tph=tph\n",
        "        relation.pr=pr\n",
        "    return relations"
      ],
      "metadata": {
        "id": "U1uxB-oa960O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validarTripletaSeudoTyped(sujeto=None, relation=None, obj=None, tripletas=None):\n",
        "    \n",
        "    if sujeto!=None:\n",
        "        if relation!=None:\n",
        "            for triple in tripletas:\n",
        "                temp=triple.split('\\t')\n",
        "                if temp[0]==sujeto and temp[1]==relation:\n",
        "                    return True                \n",
        "    elif obj!=None:\n",
        "        if relation!=None:\n",
        "            for triple in tripletas:\n",
        "                temp=triple.split('\\t')\n",
        "                if temp[2]==obj and temp[1]==relation:\n",
        "                    return True                \n",
        "    return False "
      ],
      "metadata": {
        "id": "pltv9qKt9_TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor(object):\n",
        "    def get_train_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []            \n",
        "            for line in reader:\n",
        "                lines.append(line)  \n",
        "            return lines  "
      ],
      "metadata": {
        "id": "kXmUvdMr-Hcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KGProcessor(DataProcessor):\n",
        "    def __init__(self):\n",
        "        self.labels = set()\n",
        "    \n",
        "    def get_train_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train_reduced_11082.tsv\")), \"train\", data_dir)\n",
        "        \n",
        "    def _create_examples(self, lines, set_type, data_dir):       \n",
        "\n",
        "        examples = [] \n",
        "         \n",
        "        train_with_corrupts=[]  \n",
        "\n",
        "        examples_file=os.path.join(data_dir, \"train_reduced_11082_neg_and_descrip_seudotyped.tsv\")\n",
        "        train_with_corrupts_file=os.path.join(data_dir, \"train_reduced_11082_neg_seudotyped.tsv\")\n",
        "        \n",
        "        ent2text = {}\n",
        "        with open(os.path.join(data_dir, \"entity2text.txt\"), 'r', encoding=\"utf-8\") as f:\n",
        "            ent_lines = f.readlines()\n",
        "            for line in tqdm(ent_lines):\n",
        "                temp = line.strip().split('\\t')\n",
        "                if len(temp) == 2:\n",
        "                    ent2text[temp[0]] = temp[1]      \n",
        "        entities = list(ent2text.keys())\n",
        "\n",
        "              \n",
        "        rel2text = {}\n",
        "        with open(os.path.join(data_dir, \"relation2text.txt\"), 'r', encoding=\"utf-8\") as f:\n",
        "            rel_lines = f.readlines()\n",
        "            for line in rel_lines:\n",
        "                temp = line.strip().split('\\t')                \n",
        "                rel2text[temp[0]] = temp[1]\n",
        "\n",
        "        lines_str_set = set(['\\t'.join(line) for line in lines])\n",
        "        \n",
        "        \n",
        "        #GoodNegativeSampler with Bernoulli\n",
        "        relations_dom_ran=[] \n",
        "        with open(os.path.join(data_dir, \"relations_dom_ran.txt\"), 'r', encoding=\"utf-8\") as ff:\n",
        "            relations_dom_ran_lines = ff.readlines()\n",
        "            for line_relation_dom_ran in tqdm(relations_dom_ran_lines):\n",
        "                temp_relation_dom_ran = line_relation_dom_ran.strip().split('\\t')\n",
        "                relations_dom_ran.append(Relation_Dom_Ran(relation=temp_relation_dom_ran[0], dom=temp_relation_dom_ran[1], rang=temp_relation_dom_ran[2]))               \n",
        "        relations_dom_ran=CalcularBernoulliDistribution(relations_dom_ran, lines_str_set)\n",
        "        \n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "         \n",
        "            print(\"******i\", i)\n",
        "            head_ent_text = ent2text[line[0]]\n",
        "            tail_ent_text = ent2text[line[2]]\n",
        "            relation_text = rel2text[line[1]]\n",
        "            guidP = \"%s-%s\" % (set_type, i)\n",
        "\n",
        "            #Corrupting head or tail according to GoodNegativeSampler with Bernoulli\n",
        "            headOrTail=[\"head\",\"tail\"] \n",
        "            headProbability, tailProbability=0,0\n",
        "                        \n",
        "            prs=[relation_dom_ran_aux.pr for relation_dom_ran_aux in relations_dom_ran if relation_dom_ran_aux.relation==line[1]]\n",
        "            if len(prs)>0:\n",
        "                headProbability=prs[0]\n",
        "                tailProbability=1-headProbability\n",
        "            rnd=random.choices(headOrTail, weights=(headProbability, tailProbability), k=1)\n",
        "                        \n",
        "            guidN = \"%s-%s\" % (set_type + \"_corrupt\", i) \n",
        "            good_triple_flag=False\n",
        "\n",
        "            if rnd[0]==\"head\":\n",
        "                tmp_head = ''\n",
        "                cant=0\n",
        "                while True:\n",
        "                    cant=cant+1\n",
        "                    tmp_ent_list = set(entities)\n",
        "                    tmp_ent_list.remove(line[0])\n",
        "                    tmp_ent_list = list(tmp_ent_list)\n",
        "                    tmp_head = random.choice(tmp_ent_list)\n",
        "                    tmp_triple_str = tmp_head + '\\t' + line[1] + '\\t' + line[2]\n",
        "                    if tmp_triple_str not in lines_str_set:\n",
        "                        good_triple_flag=validarTripletaSeudoTyped(sujeto=tmp_head, relation=line[1], obj=None, tripletas=lines_str_set)\n",
        "                        if good_triple_flag:\n",
        "                            break\n",
        "                        if cant==800:\n",
        "                            break\n",
        "                if good_triple_flag:\n",
        "                    examples.append(InputExample(guid=guidP, text_a=head_ent_text, text_b=relation_text, text_c = tail_ent_text, label=\"1\"))\n",
        "                    train_with_corrupts.append(Triple(guid=guidP,subject= line[0], predicate=line[1], obj=line[2], label=\"1\"))\n",
        "\n",
        "                    tmp_head_text = ent2text[tmp_head]       \n",
        "                    examples.append(InputExample(guid=guidN, text_a=tmp_head_text, text_b=relation_text, text_c = relation_text, label=\"0\")) \n",
        "                    train_with_corrupts.append(Triple(guid=guidN,subject=tmp_head, predicate=line[1], obj=line[2], label=\"0\"))\n",
        "            else:\n",
        "                tmp_tail = ''\n",
        "                cant=0\n",
        "                while True:\n",
        "                    cant=cant+1\n",
        "                    tmp_ent_list = set(entities)\n",
        "                    tmp_ent_list.remove(line[2])\n",
        "                    tmp_ent_list = list(tmp_ent_list)\n",
        "                    tmp_tail = random.choice(tmp_ent_list)\n",
        "                    tmp_triple_str = line[0] + '\\t' + line[1] + '\\t' + tmp_tail\n",
        "                    if tmp_triple_str not in lines_str_set:\n",
        "                        good_triple_flag=validarTripletaSeudoTyped(sujeto=None, relation=line[1], obj=tmp_tail, tripletas=lines_str_set)\n",
        "                        if good_triple_flag:\n",
        "                            break\n",
        "                        if cant==800:\n",
        "                            break\n",
        "                if good_triple_flag:\n",
        "                    examples.append(InputExample(guid=guidP, text_a=head_ent_text, text_b=relation_text, text_c = tail_ent_text, label=\"1\"))\n",
        "                    train_with_corrupts.append(Triple(guid=guidP,subject= line[0], predicate=line[1], obj=line[2], label=\"1\"))\n",
        "\n",
        "                    tmp_tail_text = ent2text[tmp_tail]\n",
        "                    examples.append(InputExample(guid=guidN, text_a=head_ent_text, text_b=relation_text, text_c = tmp_tail_text, label=\"0\"))  \n",
        "                    train_with_corrupts.append(Triple(guid=guidN,subject= line[0] , predicate=line[1], obj=tmp_tail, label=\"0\"))\n",
        "        \n",
        "        with open(examples_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "                for sample in examples:\n",
        "                    writer.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (sample.guid, sample.text_a, sample.text_b, sample.text_c, sample.label))\n",
        "        \n",
        "        #Generando los ejemplos a utilizar en entrenamiento\n",
        "        with open(train_with_corrupts_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "                for triple in train_with_corrupts:\n",
        "                   writer.write(\"%s\\t%s\\t%s\\t%s\\n\" % (triple.subject, triple.predicate, triple.obj, triple.label))\n",
        "        return examples "
      ],
      "metadata": {
        "id": "-QRPltzn-Kvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "        \n",
        "    arg_dict ={\n",
        "        \"task_name\": \"kg\",\n",
        "        \"data_dir\": data_dir,      \n",
        "        }\n",
        "    processors = {\n",
        "        \"kg\": KGProcessor,\n",
        "        }  \n",
        "    task_name = arg_dict[\"task_name\"].lower()\n",
        "    processor = processors[task_name]()\n",
        " \n",
        "    train_examples = processor.get_train_examples(arg_dict[\"data_dir\"])   \n",
        "    print(\"len(train_examples)\",len(train_examples))  "
      ],
      "metadata": {
        "id": "nD5Y-IvV-M8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()    "
      ],
      "metadata": {
        "id": "WbZ6AYfi-OcM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}