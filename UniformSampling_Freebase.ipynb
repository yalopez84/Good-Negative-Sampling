{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1uUVMtrFFJqn4VnXy8n5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yalopez84/Goog-Negative-Sampling/blob/master/UniformSampling_Freebase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTaWYx3Z7pXY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm, trange\n",
        "import random\n",
        "import csv\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir=\"/content/drive/MyDrive/NegativeStrategies/GoodNegativeSampling/FB13/\"\n",
        "os.chdir(data_dir)  \n"
      ],
      "metadata": {
        "id": "kb7f7KZQ7thk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputExample(object):    \n",
        "    def __init__(self, guid, text_a, text_b=None, text_c=None, label=None):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.text_c = text_c\n",
        "        self.label = label"
      ],
      "metadata": {
        "id": "SPoSzY5d7vzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Triple(object):\n",
        "    def __init__(self, guid, subject , predicate , obj, label):\n",
        "        self.guid=guid\n",
        "        self.subject=subject\n",
        "        self.predicate=predicate\n",
        "        self.obj=obj\n",
        "        self.label=label"
      ],
      "metadata": {
        "id": "Y9wtEh3C7x89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor(object):\n",
        "    def get_train_examples(self, data_dir):\n",
        "        raise NotImplementedError()\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []            \n",
        "            for line in reader:\n",
        "                lines.append(line)  \n",
        "            return lines  "
      ],
      "metadata": {
        "id": "q7eSkk8Z70PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KGProcessor(DataProcessor):\n",
        "    def __init__(self):\n",
        "        self.labels = set()\n",
        "    \n",
        "    def get_train_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train_reduced_11082.tsv\")), \"train\", data_dir)\n",
        "        \n",
        "    def _create_examples(self, lines, set_type, data_dir):       \n",
        "\n",
        "        examples = [] \n",
        "         \n",
        "        train_with_corrupts=[]  \n",
        "\n",
        "        examples_file=os.path.join(data_dir, \"train_reduced_11082_neg_and_descrip_kgbert.tsv\")\n",
        "        train_with_corrupts_file=os.path.join(data_dir, \"train_reduced_11082_neg_kgbert.tsv\")\n",
        "        \n",
        "        ent2text = {}\n",
        "        with open(os.path.join(data_dir, \"entity2text.txt\"), 'r', encoding=\"utf-8\") as f:\n",
        "            ent_lines = f.readlines()\n",
        "            for line in tqdm(ent_lines):\n",
        "                temp = line.strip().split('\\t')\n",
        "                if len(temp) == 2:\n",
        "                    ent2text[temp[0]] = temp[1]      \n",
        "        entities = list(ent2text.keys())\n",
        "\n",
        "              \n",
        "        rel2text = {}\n",
        "        with open(os.path.join(data_dir, \"relation2text.txt\"), 'r', encoding=\"utf-8\") as f:\n",
        "            rel_lines = f.readlines()\n",
        "            for line in rel_lines:\n",
        "                temp = line.strip().split('\\t')                \n",
        "                rel2text[temp[0]] = temp[1]       \n",
        "        lines_str_set = set(['\\t'.join(line) for line in lines])\n",
        "        \n",
        "                      \n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i==6526:\n",
        "                 break\n",
        "            print(\"******i\", i)\n",
        "            head_ent_text = ent2text[line[0]]\n",
        "            tail_ent_text = ent2text[line[2]]\n",
        "            relation_text = rel2text[line[1]]\n",
        "            guidP = \"%s-%s\" % (set_type, i)\n",
        "\n",
        "                       \n",
        "            guidN = \"%s-%s\" % (set_type + \"_corrupt\", i) \n",
        "            rnd = random.random()\n",
        "            if rnd <= 0.5:\n",
        "                tmp_head = ''\n",
        "                while True:\n",
        "                    \n",
        "                    tmp_ent_list = set(entities)\n",
        "                    tmp_ent_list.remove(line[0])\n",
        "                    tmp_ent_list = list(tmp_ent_list)\n",
        "                    tmp_head = random.choice(tmp_ent_list)\n",
        "                    tmp_triple_str = tmp_head + '\\t' + line[1] + '\\t' + line[2]\n",
        "                    if tmp_triple_str not in lines_str_set:\n",
        "                            break\n",
        "                examples.append(InputExample(guid=guidP, text_a=head_ent_text, text_b=relation_text, text_c = tail_ent_text, label=\"1\"))\n",
        "                train_with_corrupts.append(Triple(guid=guidP,subject= line[0], predicate=line[1], obj=line[2], label=\"1\"))\n",
        "\n",
        "                tmp_head_text = ent2text[tmp_head]       \n",
        "                examples.append(InputExample(guid=guidN, text_a=tmp_head_text, text_b=relation_text, text_c = relation_text, label=\"0\")) \n",
        "                train_with_corrupts.append(Triple(guid=guidN,subject=tmp_head, predicate=line[1], obj=line[2], label=\"0\"))\n",
        "            else:\n",
        "                tmp_tail = ''\n",
        "                while True:\n",
        "                    tmp_ent_list = set(entities)\n",
        "                    tmp_ent_list.remove(line[2])\n",
        "                    tmp_ent_list = list(tmp_ent_list)\n",
        "                    tmp_tail = random.choice(tmp_ent_list)\n",
        "                    tmp_triple_str = line[0] + '\\t' + line[1] + '\\t' + tmp_tail\n",
        "                    if tmp_triple_str not in lines_str_set:\n",
        "                            break\n",
        "                examples.append(InputExample(guid=guidP, text_a=head_ent_text, text_b=relation_text, text_c = tail_ent_text, label=\"1\"))\n",
        "                train_with_corrupts.append(Triple(guid=guidP,subject= line[0], predicate=line[1], obj=line[2], label=\"1\"))\n",
        "\n",
        "                tmp_tail_text = ent2text[tmp_tail]\n",
        "                examples.append(InputExample(guid=guidN, text_a=head_ent_text, text_b=relation_text, text_c = tmp_tail_text, label=\"0\"))  \n",
        "                train_with_corrupts.append(Triple(guid=guidN,subject= line[0] , predicate=line[1], obj=tmp_tail, label=\"0\"))\n",
        "        \n",
        "        with open(examples_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "                for sample in examples:\n",
        "                    writer.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (sample.guid, sample.text_a, sample.text_b, sample.text_c, sample.label))\n",
        "        \n",
        "        #Generando los ejemplos a utilizar en entrenamiento\n",
        "        with open(train_with_corrupts_file, \"w\", encoding=\"utf-8\") as writer:\n",
        "                for triple in train_with_corrupts:\n",
        "                   writer.write(\"%s\\t%s\\t%s\\t%s\\n\" % (triple.subject, triple.predicate, triple.obj, triple.label))\n",
        "        return examples "
      ],
      "metadata": {
        "id": "jW8Kvf7H72l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "        \n",
        "    arg_dict ={\n",
        "        \"task_name\": \"kg\",\n",
        "        \"data_dir\": data_dir,      \n",
        "        }\n",
        "    processors = {\n",
        "        \"kg\": KGProcessor,\n",
        "        }  \n",
        "    task_name = arg_dict[\"task_name\"].lower()\n",
        "    processor = processors[task_name]()\n",
        " \n",
        "    train_examples = processor.get_train_examples(arg_dict[\"data_dir\"])   \n",
        "    print(\"len(train_examples)\",len(train_examples))  "
      ],
      "metadata": {
        "id": "N4sjg9EI77GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "5DWSidbp78mr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}